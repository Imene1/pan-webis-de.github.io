<!DOCTYPE html>
<html lang="en">
<head>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>PAN 2016</title> 

<link href="../../css/bootstrap.min.css" rel="stylesheet" />
<link href="../../css/prettify.css" rel="stylesheet" />

<style>
.navbar .navbar-nav {
  font-weight: bold;
}
</style>

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
  <script src="../../js/html5shiv.js"></script>
  <script src="../../js/respond.min.js"></script>
<![endif]-->

<link rel="shortcut icon" href="../pan16-figures/pan-icon-16x16.ico">
<!--
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="ico/apple-touch-icon-144-precomposed.png">
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="ico/apple-touch-icon-114-precomposed.png">
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="ico/apple-touch-icon-72-precomposed.png">
<link rel="apple-touch-icon-precomposed" href="ico/apple-touch-icon-57-precomposed.png">
-->

</head>
<body>

<nav class="navbar navbar-inverse navbar-static-top" role="navigation">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="../../index.html"><img src="../pan16-figures/pan-logo-small-lightgrey.png" alt="PAN" style="margin-top:-5px"></a>
  </div>
  <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
    <ul class="nav navbar-nav navbar-right">
      <li><a href="../../index.html">Home</a></li>
      <li><a href="index.html">PAN @ CLEF 2016:</a></li>
      <li><a href="about.html">About</a></li>
      <li><a href="proceedings.html">Proceedings</a></li>
      <li class="dropdown active">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Tasks <span class="caret"></span></a>
        <ul class="dropdown-menu">
          <li class="active"><a href="author-identification.html">Author Identification</a></li>
          <li><a href="author-profiling.html">Author Profiling</a></li>
          <li><a href="author-obfuscation.html">Author Obfuscation</a></li>
        </ul>
      </li>
    </ul>
  </div>
</nav>

<div class="container">

<div class="row">
  <div class="col-xs-12">
    <h1 id="task-description" class="page-header">
      Author Identification
      <div class="btn-group">
        <a role="button" class="btn btn-default" href="../../clef15/pan15-web/author-identification.html"><span class="glyphicon glyphicon-chevron-left" style="color:grey;"></span></a>
        <span role="button" class="btn btn-default" disabled="disabled">2016</span>
        <span role="button" class="btn btn-default" disabled="disabled"><span class="glyphicon glyphicon-chevron-right" style="color:grey;"></span></span>
      </div>
    </h1>
    <p class="lead">This task is divided into <strong>author clustering</strong> and <strong>author diarization</strong>. You can choose to solve one or both of them.</p>
    <ul class="nav nav-pills visible-xs">
      <li><a href="#author-clustering" class="btn btn-large"><span class="glyphicon glyphicon-chevron-down"></span> Author Clustering</a></li>
      <li><a href="#author-diarization" class="btn btn-large"><span class="glyphicon glyphicon-chevron-down"></span> Author Diarization</a></li>
    </ul>
  </div>
</div>

<div class="row">
  <div class="col-sm-6">
    <h2 id="author-clustering">Author Clustering</h2>
    <p>Authorship attribution is an important problem in information retrieval and computational linguistics but also in applied areas such as law and journalism where knowing the author of a document (such as a ransom note) may be able to save lives. The most common framework for testing candidate algorithms is the closed-set attribution task: given known sample documents from a small, finite set of candidate authors, which wrote a questioned document of unknown authorship? It has been commented, however, that this may be an unreasonably easy task. A more demanding task is <strong>author clustering</strong> where given a document collection the task is to group documents written by the same author so that each cluster corresponds to a different author. This task can also be viewed as establishing <strong>authorship links</strong> between documents. </p>
	<p>Note that a variation of author clustering was included in the PAN-2012 edition. However, it was focused on the paragraph-level and therefore it is more related to the author diarization task (see details in the right column). In PAN-2016, we focus on <strong>document-level author clustering</strong>. The task of authorship verification studied in detail in previous editions of PAN (2013-2015) is strongly associated with author clustering since any clustering problem can be decomposed into a series of author verification problems. We encourage participants to attempt to modify authorship verification approaches to deal with the author clustering task.</p>
	<p>In this edition of PAN we aim to study two application scenarios: </p>
	<ul>
	<li><strong>Complete author clustering</strong>: This scenario requires a detailed analysis where the number (k) of different authors found in the collection should be identified and each document should be assigned to exactly one of the k clusters (each cluster corresponds to a different author). </li>
		<p align="center"><img src="https://cloud.githubusercontent.com/assets/15824066/12065874/81d95440-afe7-11e5-828b-54e293540823.png"/></p>
	<li>-	<strong>Authorship-link ranking</strong>: This scenario views the exploration of the given document collection as a retrieval task. It aims at establishing authorship links between documents and provides a list of document pairs ranked according to a confidence score (the score shows how likely it is the document pair to be by the same author).</li>
		<p align="center"><img src="https://cloud.githubusercontent.com/assets/15824066/12065971/f2a087e2-afe8-11e5-9ef4-6df4e5aff9ae.png"/></p>
	</ul>
    <div class="panel panel-default">
      <div class="panel-heading">Task</div>
      <div class="panel-body">Given a collection of documents, identify authorship links and groups of documents by the same author. All documents are single-authored, in the same language, and belong to the same genre. However, the topic or text-length of documents may vary. The number of distinct authors whose documents are included in the collection is not given.</div>
    </div>
    <!--
    <div class="panel panel-default">
      <div class="panel-heading">Training Phase</div>
      <div class="panel-body"><p>To develop your software, we provide you with a training corpus that comprises a set of author verification problems in several languages/genres. Each problem consists of some (up to five) known documents by a single person and exactly one questioned document. All documents within a single problem instance will be in the same language. 
		  However, their genre and/or topic may differ 
		  significantly. The document lengths vary from a few hundred to a few thousand words.</p>
		  <p>
		  <a class="btn btn-default" target="_blank" href="http://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-15/pan15-data/pan15-authorship-verification-training-dataset-2015-04-19.zip">Download corpus</a> (Update April 19, 2015)
		  </p><p>
		  The documents of each problem are located in a separate folder, 
		  the name of which (problem ID) encodes the language of the 
		  documents. The following list shows the available sub-corpora, including their language, type (cross-genre or cross-topic), code, and examples of problem IDs:
		  <br><table class="table table-condensed rule" style="font-size:small;">
        <thead>
        <tr><th>Language</th><th>Type</th><th>Code</th><th>Problem IDs</th></tr>
        </thead>
        <tbody>
        <tr><td>Dutch</td><td>
			Cross-genre</td><td>DU</td><td>
			DU001, DU002,
			DU003, etc.</td></tr>
        <tr><td>English</td><td>Cross-topic</td><td>EN</td><td>
			EN001, EN002, 
			EN003, etc.</td></tr>
        <tr><td>Greek</td><td>Cross-topic</td><td>GR</td><td>GR001, GR002, GR003, etc.</td></tr>
        <tr><td>Spanish</td><td>Cross-genre</td><td>SP</td><td>SP001, SP002, SP003, etc.</td></tr>
        </tbody>
        </table>
		  <br>The ground truth data of the training corpus found in the file <code>truth.txt</code> include one line per problem with problem ID and the correct binary answer (Y means the known and the questioned documents are 
		  by the same author and N means the opposite). 
		  For example: <br>
        <pre class="prettyprint lang-py" style="overflow-x:auto">
EN001 N
EN002 Y
EN003 N
...
		</pre>
  </p>
</div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Evaluation Phase</div>
      <div class="panel-body">Once you finished tuning your approach to achieve satisfying performance on the training corpus, your software will be tested on the evaluation corpus. During the competition, the evaluation corpus will not be released publicly. Instead, we ask you to submit your software for evaluation at our site as described below.
<br>After the competition, the evaluation corpus will become available including ground truth data. This way, you have all the necessities to evaluate your approach on your own, yet being comparable to those who took part in the competition.
</div></div>
    <div class="panel panel-default">
      <div class="panel-heading">Output</div>
      <div class="panel-body">Your software must take as input the absolute path to a set of problems. For each problem there is a separate sub-folder within that path including the set of known documents and the single unknown document of that problem (similarly to the training corpus). The software has to output a single text file <code>answers.txt</code> with all the produced answers for the whole set of evaluation problems. Each line of this file corresponds to a problem instance, it starts with the ID of the problem followed by a score, a real number in [0,1] inclusive, corresponding to the probability of a positive answer. That is, 0 means it is absolutely sure the questioned document is not by the author of the known documents, 1.0 means it is absolutely sure the questioned document and the known documents are by the same author, and 0.5 means that a positive and a negative answer are equally likely. The probability scores should be round with three decimal digits. Use a single whitespace to separate problem ID and probability score.
<br>For example, an <code>answers.txt</code> file may look like this:
<pre class="prettyprint lang-py" style="overflow-x:auto">
EN001 0.031
EN002 0.874
EN003 0.500
...
</pre>
&nbsp;</div></div>
-->
    <div class="panel panel-default">
      <div class="panel-heading">Performance Measures</div>
      <div class="panel-body">
      	<ul>
      		<li>The clustering output will be evaluated according to <strong>BCubed, recall, precision, and F-score</strong> (<a href="http://nlp.uned.es/docs/amigo2007a.pdf">Amigo et al. 2007</a>)</li>
      		<li>The ranking of authorship links will be evaluated according to <strong>average precision</strong> (<a href="http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html">Manning et al. 2008</a>)</li>
 	</ul>
	</div></div>
<!--    
	  <div class="panel panel-default">
      <div class="panel-heading">Submission</div>
      <div class="panel-body">
        <p>We ask you to prepare your software so that it can be executed via command line calls. To maximize the sustainability of software submissions for this task, we encourage you to prepare your software so it can be re-trained on demand, i.e., by offering two commands, one for training, and one for testing. This way, your software can be reused on future evaluation corpora as well as on private collections submitted to PAN by via our data submission initiative.</p>
        <p>The training command shall take as input (i) an absolute path to a training corpus formated as described above, and (ii) an absolute path to an empty output directory:</p>
        <pre class="prettyprint lang-c" style="overflow-x:auto">
> myTrainingSoftware <b>-i</b> path/to/training/corpus <b>-o</b> path/to/output/directory
</pre>
        <p>Based on the training corpus, and perhaps based on its language and genre found within, your software shall train a classification model, and save the trained model to the specified output directory in serialized or binary form.</p>
        <p>The testing command shall take as input (i) an absolute path to a test corpus (not containing the ground truth) (ii) an absolute path to a previously trained classification model, and (iii) an absolute path to an empty output directory:</p>
        <pre class="prettyprint lang-py" style="overflow-x:auto">
> myTestingSoftware <b>-i</b> path/to/test/corpus <b>-m</b> path/to/classification/model <b>-o</b> path/to/output/directory
</pre>
        <p>Based on the classification model, the software shall classifiy each case found in the test corpus and write an output file as described above to the output directory.</p>
        <p>However, <b>offering a command for training is optional</b>, so if you face difficulties in doing so, you may skip the training command and omit the model option <b>-m</b> from the testing command.</p>
        <p>You can choose freely among the available programming languages and among the operating systems Microsoft Windows and Ubuntu. We will ask you to deploy your software onto a virtual machine that will be made accessible to you after registration. You will be able to reach the virtual machine via ssh and via remote desktop. More information about how to access the virtual machines can be found in the user guide below:</p>
        <p><a class="btn btn-default" href="pan15-virtual-machine-user-guide.pdf">PAN Virtual Machine User Guide »</a></p>
        <p>Once deployed in your virtual machine, we ask you to access TIRA at <a href="http://www.tira.io">www.tira.io</a>, where you can self-evaluate your software on the test data.</p>
        <p><strong>Note:</strong> By submitting your software you retain full copyrights. You agree to grant us usage rights only for the purpose of the PAN competition. We agree not to share your software with a third party or use it for other purposes than the PAN competition.</p>
      </div>
    </div>
    
    <div class="panel panel-default">
      <div class="panel-heading">Similarities/Differences with PAN-2014</div>
      <div class="panel-body">For your convenience, we summarize here the main similarities/differences of the author identification task @PAN-2015 with respect to the corresponding task @PAN-2014:
<br><br>Similarities:
<ul>
<li>The task definition is essentially the same</li>
<li>The format of corpus and ground truth is the same</li>
	<li>The format of input/output of your software is the 
	same</li>
<li>The positive/negative problems are equally distributed</li>
	<li>The evaluation measures are the same</li>
	<li>It is possible (optionally) to submit a trainable version of your approach to be used with any given training corpus</li>
</ul>
Differences:
<ul>
<li>The genre and/or topic of the documents within a 
verification problem may differ significantly.</li>
</ul>

</div></div>
-->

    <div class="panel panel-default">
      <div class="panel-heading">Related Work</div>
      <div class="panel-body">
        <p>We refer you to:</p>
        <ul><li>
			<a href="../../clef15/pan15-web/proceedings.html">PAN@CLEF'15</a></li>
			<li>
        	<a href="../../clef13/pan13-web/proceedings.html">PAN@CLEF'13</a>
        </li><li>
			<a href="../../clef14/pan14-web/proceedings.html">PAN@CLEF'14</a></li>
			<li>
        	<a href="../../clef13/pan13-web/proceedings.html">PAN@CLEF'13</a>
        </li><li>
        <a href="../../clef12/pan12-web/proceedings.html">PAN@CLEF'12</a>
        </li><li>
        <a href="../../clef11/pan11-web/proceedings.html">PAN@CLEF'11</a>
        </li><li>
        Patrick Juola. <a href="http://portal.acm.org/citation.cfm?id=1373451">Authorship Attribution</a>. In Foundations and Trends in Information Retrieval, Volume 1, Issue 3, March 2008.
        </li><li>
        Moshe Koppel, Jonathan Schler, and Shlomo Argamon. <a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.20961/full">Computational Methods
        Authorship Attribution</a>. Journal of the American Society for Information Science and Technology, Volume 60, Issue 1, pages 9-26, January 2009.
        </li><li>
        Efstathios Stamatatos. <a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.21001/full">A Survey of Modern Authorship Attribution Methods</a>.
        Journal of the American Society for Information Science and Technology, Volume 60, Issue 3, pages 538-556, March 2009.
        </li></ul>
      </div>
    </div>
    <div id="task-committee" class="row">
      <div class="col-xs-12">
        <h2 class="page-header">Task Chair</h2>
      </div>
    </div>
    <div class="row">
      <div class="col-xs-6">
        <div class="thumbnail" style="text-align:center;">
          <a href="http://www.icsd.aegean.gr/lecturers/stamatatos/" target="_blank"><img src="../pan16-figures/stathis.jpg" class="img-rounded" alt="Efstathios Stamatatos"></a>
          <p><a href="http://www.icsd.aegean.gr/lecturers/stamatatos/" target="_blank">Efstathios Stamatatos</a></p>
          <p style="font-size:10pt">University of the Aegean</p>
        </div>
      </div>
    </div>
    <div class="row">
      <div class="col-xs-12">
        <h2>Task Committee</h2>
      </div>
    </div>
    <div class="row">
      <div class="col-xs-6">
        <div class="thumbnail" style="text-align:center;">
          <a href="http://www.clips.ua.ac.be/~walter/" target="_blank"><img src="../pan16-figures/walter.jpg" class="img-rounded" alt="Walter Daelemans"></a>
          <p style="white-space:nowrap"><a href="http://www.clips.ua.ac.be/~walter/" target="_blank">Walter Daelemans</a></p>
          <p style="font-size:10pt">University of Antwerp</p>
        </div>
      </div>
      <div class="col-xs-6">
        <div class="thumbnail" style="text-align:center;">
          <a href="http://www.mathcs.duq.edu/~juola/" target="_blank"><img src="../pan16-figures/patrick.jpg" class="img-rounded" alt="Patrick Juola"></a>
          <p style="white-space:nowrap"><a href="http://www.mathcs.duq.edu/~juola/" target="_blank">Patrick Juola</a></p>
          <p style="font-size:10pt">Duquesne University</p>
        </div>
      </div>
      <div class="col-xs-6">
        <div class="thumbnail" style="text-align:center;">
          <a href="http://www.uni-weimar.de/medien/webis/people" target="_blank"><img src="../pan16-figures/martin.jpg" class="img-rounded" alt="Martin Potthast"></a>
          <p style="white-space:nowrap"><a href="http://www.uni-weimar.de/medien/webis/people" target="_blank">Martin Potthast</a></p>
          <p style="font-size:10pt">Bauhaus-Universit&auml;t Weimar</p>
        </div>
      </div>
      <div class="col-xs-6">
        <div class="thumbnail" style="text-align:center;">
          <a href="http://www.webis.de" target="_blank"><img src="../pan16-figures/benno.jpg" class="img-rounded" alt="Benno Stein"></a>
          <p style="white-space:nowrap"><a href="http://www.webis.de" target="_blank">Benno Stein</a></p>
          <p style="font-size:10pt">Bauhaus-Universit&auml;t Weimar</p>
        </div>
      </div>
    </div>
  </div>

  <div class="col-sm-6">
    <h2 id="source-retrieval">Author Diarization <small>or Intrinsic Plagiarism Detection</small></h2>
    <div class="panel panel-default">
      <div class="panel-heading">Task</div>
      <div class="panel-body">Given a document, the task is to divide it into groups of fragments written by the same author.</div>
    </div>
    <!--
    <div class="panel panel-default">
      <div class="panel-heading">Training Corpus</div>
      <div class="panel-body">
        <p>To develop your software, we provide you with a training corpus that consists of suspicious documents. Each suspicious document is about a specific topic and may consist of plagiarized passages obtained from web pages on that topic found in the ClueWeb09 corpus.</p>
        <p>
          <a class="btn btn-default" href="http://www.uni-weimar.de/medien/webis/publications/papers/stein_2013f.pdf">Learn more »</a>
          <a class="btn btn-default" target="_blank" href="http://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-14/pan14-data/pan14-source-retrieval-training-corpus-2014-12-01.zip">Download corpus</a>
        </p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">API</div>
      <div class="panel-body">
        <p>If you are not in possession of the <a href="http://www.lemurproject.org/clueweb09.php/" target="_blank">ClueWeb09 corpus</a>, we also provide access to two search engines which index the ClueWeb, namely the <a href="http://www.lemurproject.org/indri/" target="_blank">Lemur Indri search engine</a> and the <a href="http://chatnoir.webis.de" target="_blank">ChatNoir search engine</a>. To programmatically access these two search engines, we provide a unified search API.</p>
        <p><a class="btn btn-default" href="http://webis15.medien.uni-weimar.de/pan/">Learn more »</a></p>
        <p><strong>Note:</strong> To better separate the source retrieval task from the text alignment task, the API provides a text alignment oracle feature. For each document you request to download from the ClueWeb, the text alignment oracle discloses if this document is a source for plagiarism for the suspicious document in question. In addition, the plagiarized text is returned. This, way participation in the source retrieval task does not require the development of a text alignment solution. However, you are free to use your own text alignment, if you want to.</p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Baseline</div>
      <div class="panel-body">
        <p>For your convenience, we provide a baseline program written in Python.</p>
        <p><a class="btn btn-default" href="../../clef12/pan12-code/pan12-source-retrieval-baseline.py">Download program</a></p>
        <p>The program loops through the suspicious documents in a given directory and outputs a search interaction log. The log is valid with respect to the output format described below. You may use the source code for getting started with your own approach.</p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Output</div>
      <div class="panel-body">
        <p>For each suspicious document <code>suspicious-documentXYZ.txt</code> found in the evaluation corpora, your plagiarism detector shall output an interaction log <code>suspicious-documentXYZ.log</code> which logs meta information about your retrieval process:</p>
<pre class="prettyprint lang-py" style="overflow-x:auto;white-space:nowrap">
Timestamp&nbsp;&nbsp;&nbsp;[Query|Download_URL]<br/>
1358326592&nbsp;&nbsp;barack obama family tree<br/>
1358326597&nbsp;&nbsp;http://webis15.medien.uni-weimar.de/proxy/clueweb/id/110212744<br/>
1358326598&nbsp;&nbsp;http://webis15.medien.uni-weimar.de/proxy/clueweb/id/10221241<br/>
1358326599&nbsp;&nbsp;http://webis15.medien.uni-weimar.de/proxy/clueweb/id/100003305377<br/>
1358326605&nbsp;&nbsp;barack obama genealogy<br/>
1358326610&nbsp;&nbsp;http://webis15.medien.uni-weimar.de/proxy/clueweb/id/82208332<br/>
...
</pre>
        <p>For example, the above file would specify that at 1358326592 (Unix timestamp) the query <code>barack obama family tree</code> was sent and that in the following three of the retrieved documents were selected for download before the next query was sent.</p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Performance Measures</div>
      <div class="panel-body">
        <p>
        Performance will be measured based on the following five scores as averages over each suspicious document:
        </p><ol><li>
        Number of queries submitted.
        </li><li>
        Number of web pages downloaded.
        </li><li>
        Precision and recall of web pages downloaded regarding actual sources of a suspicious document.
        </li><li>
        Number of queries until the first actual source is found.
        </li><li>
        Number of downloads until the first actual source is downloaded.
        </li></ol><p>
        Measures 1-3 capture the overall behavior of a system and measures 4-5 assess the time to first result. The quality of identifying reused passages between documents is not taken into account here, but note that retrieving duplicates of a source document is considered a true positive, whereas retrieving more than one duplicate of a source document does not improve performance.
        </p>
        <p>
          <a class="btn btn-default" href="http://www.uni-weimar.de/medien/webis/publications/papers/stein_2013h.pdf#page=6">Learn more »</a>
        </p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Test Corpus</div>
      <div class="panel-body">
        <p>Once you finished tuning your approach to achieve satisfying performance on the training corpus, you should run your software on the test corpus.</p>
        <p>During the competition, the test corpus will not be released publicly. Instead, we ask you to submit your software for evaluation at our site as described below.</p>
        <p>After the competition, the test corpus is available including ground truth data. This way, you have all the necessities to evaluate your approach on your own, yet being comparable to those who took part in the competition.</p>
        <p>
          <a class="btn btn-default" target="_blank" href="http://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan14/pan14-data/">Download corpus</a>
        </p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Submission</div>
      <div class="panel-body">
        <p>We ask you to prepare your software so that it can be executed via a command line call.</p>
        <pre class="prettyprint lang-c" style="overflow-x:auto">
> mySoftware <b>-i</b> path/to/corpus <b>-o</b> path/to/output/directory <b>-t</b> accessToken
</pre>
        <p>You can choose freely among the available programming languages and among the operating systems Microsoft Windows and Ubuntu. We will ask you to deploy your software onto a virtual machine that will be made accessible to you after registration. You will be able to reach the virtual machine via ssh and via remote desktop. More information about how to access the virtual machines can be found in the user guide below:</p>
        <p><a class="btn btn-default" href="pan15-virtual-machine-user-guide.pdf">PAN Virtual Machine User Guide »</a></p>
        <p>Once deployed in your virtual machine, we ask you to access TIRA at <a href="http://www.tira.io">www.tira.io</a>, where you can self-evaluate your software on the test data.</p>
        <p><strong>Note:</strong> By submitting your software you retain full copyrights. You agree to grant us usage rights only for the purpose of the PAN competition. We agree not to share your software with a third party or use it for other purposes than the PAN competition.</p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Results</div>
      <div class="panel-body">
        <p>The following table lists the performances achieved by the participating teams:</p>
        <table class="table table-condensed rule" style="font-size:small;">
        <thead>
        <tr class="top"><th colspan="5" style="text-align:center">Source Retrieval Performance</th></tr>
        <tr class="top2"><th colspan="2" style="text-align:center">Workload to 1st Detection</th><th colspan="2" style="text-align:center">Downloaded Sources</th><th>Team</th></tr>
        <tr class="mid"><th>Queries</th><th>Downloads</th><th>Precision</th><th>Recall</th><th></th></tr>
        </thead>
        <tbody>
        <tr><td> 54.5</td><td> 33.2</td><td>0.40</td><td>0.39</td><td>Victoria Elizalde<br/>Private, Argentina</td></tr>
        <tr><td> 83.5</td><td>207.1</td><td>0.08</td><td>0.48</td><td>Leilei Kong, Yong Han, Zhongyuan Han, Haihao Yu, Qibo Wang, Tinglei Zhang , Haoliang Qi<br/>Heilongjiang Institute of Technology, China</td></tr>
        <tr><td> 60.0</td><td> 38.8</td><td>0.38</td><td>0.51</td><td>Amit Prakash and Sujan kumar Saha<br/>Birla Institute of Technology, India</td></tr>
        <tr><td> 19.5</td><td>237.3</td><td>0.08</td><td>0.40</td><td>Šimon Suchomel and Michal Brandejs<br/>Masaryk University, Czech Republic</td></tr>
        <tr><td>117.1</td><td> 14.4</td><td>0.57</td><td>0.48</td><td>Kyle Williams, Hung-Hsuan Chen, and C. Lee Giles<br/>Pennsylvania State University, USA</td></tr>
        <tr><td> 37.0</td><td> 18.6</td><td>0.54</td><td>0.45</td><td>Denis Zubarev° and Ilya Sochenkov*<br/>°Institute for Systems Analysis of Russian Academy of Sciences and *Peoples’ Friendship University of Russia, Russia</td></tr>
        </tbody>
        </table>
        <p>A more detailed analysis of the retrieval performances can be found in the overview paper accompanying this task.</p>
        <p>
          <a class="btn btn-default" href="http://www.uni-weimar.de/medien/webis/publications/papers/stein_2013h.pdf#page=11">Learn more »</a>
        </p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Related Work</div>
      <div class="panel-body">
        <p>This task has been run since PAN'12; here is a quick list of the respective proceedings and overviews:</p>
        <ul><li>
        <a href="../../clef14/pan14-web/about.html#proceedings">PAN @ CLEF'14</a> (<a href="http://www.uni-weimar.de/medien/webis/publications/papers/stein_2014k.pdf">overview paper</a>), and
        </li><li>
        <a href="../../clef13/pan13-web/about.html#proceedings">PAN @ CLEF'13</a> (<a href="http://www.uni-weimar.de/medien/webis/publications/papers/stein_2013h.pdf">overview paper</a>), and
        </li><li>
        <a href="../../clef12/pan12-web/about.html#proceedings">PAN @ CLEF'12</a> (<a href="http://www.uni-weimar.de/medien/webis/publications/papers/stein_2012t.pdf">overview paper</a>).
        </li></ul>
      </div>
    </div>
  -->
    <div id="task-committee" class="row">
      <div class="col-xs-12">
        <h2 class="page-header">Task Chair</h2>
      </div>
    </div>
    <div class="row">
      <div class="col-xs-6">
        <div class="thumbnail" style="text-align:center;">
          <a href="https://dbis-informatik.uibk.ac.at/1-1-Home.html" target="_blank"><img src="../pan16-figures/michael.png" class="img-rounded" alt="Michael Tschuggnall"></a>
          <p><a href="https://dbis-informatik.uibk.ac.at/1-1-Home.html" target="_blank">Michael Tschuggnall</a></p>
          <p style="font-size:10pt">University of Innsbruck</p>
        </div>
      </div>
    </div>
    <div class="row">
      <div class="col-xs-12">
        <h2>Task Committee</h2>
      </div>
    </div>
    <div class="row">
      <div class="col-xs-6">
        <div class="thumbnail" style="text-align:center;">
          <a href="https://dbis-informatik.uibk.ac.at/1-1-Home.html" target="_blank"><img src="../pan16-figures/guenther.jpg" class="img-rounded" alt="G&uuml;nther Specht"></a>
          <p><a href="https://dbis-informatik.uibk.ac.at/1-1-Home.html" target="_blank">G&uuml;nther Specht</a></p>
          <p style="font-size:10pt">University of Innsbruck</p>
        </div>
      </div>
      <div class="col-xs-6">
        <div class="thumbnail" style="text-align:center;">
          <a href="http://www.uni-weimar.de/medien/webis/people" target="_blank"><img src="../pan16-figures/martin.jpg" class="img-rounded" alt="Martin Potthast"></a>
          <p style="white-space:nowrap"><a href="http://www.uni-weimar.de/medien/webis/people" target="_blank">Martin Potthast</a></p>
          <p style="font-size:10pt">Bauhaus-Universit&auml;t Weimar</p>
        </div>
      </div>
      <div class="col-xs-6">
        <div class="thumbnail" style="text-align:center;">
          <a href="http://www.webis.de" target="_blank"><img src="../pan16-figures/benno.jpg" class="img-rounded" alt="Benno Stein"></a>
          <p style="white-space:nowrap"><a href="http://www.webis.de" target="_blank">Benno Stein</a></p>
          <p style="font-size:10pt">Bauhaus-Universit&auml;t Weimar</p>
        </div>
      </div>
    </div>
  </div>
</div>

<footer>
  <p class="pull-right">© pan.webis.de</p>
</footer>

</div> <!-- /container -->

<script src="../../js/jquery.js"></script>
<script src="../../js/bootstrap.min.js"></script>
<script src="../../js/prettify.js"></script>
<script>
  !function ($) {
    $(function(){
      window.prettyPrint && prettyPrint()   
    })
  }(window.jQuery)
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-70770005-1', 'auto');
  ga('send', 'pageview');

</script>

</body>
</html>

